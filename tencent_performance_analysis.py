#!/usr/bin/env python3
# è…¾è®¯äº‘ç³»ç»Ÿæ€§èƒ½åˆ†æè„šæœ¬
# åˆ†æå†…å­˜å ç”¨ã€CPUä½¿ç”¨ç‡ç­‰æ€§èƒ½æŒ‡æ ‡
# ä¸ºé˜¿é‡Œäº‘éƒ¨ç½²æä¾›ä¼˜åŒ–å»ºè®®

import requests
import json
import time
from datetime import datetime

class TencentPerformanceAnalysis:
    def __init__(self, server_ip="101.33.251.158"):
        self.server_ip = server_ip
        self.analysis_results = {
            'analysis_time': datetime.now().isoformat(),
            'server_ip': server_ip,
            'performance_metrics': {},
            'database_analysis': {},
            'optimization_recommendations': []
        }
    
    def test_elasticsearch_performance(self):
        """æµ‹è¯•Elasticsearchæ€§èƒ½æŒ‡æ ‡"""
        print("ğŸ” åˆ†æElasticsearchæ€§èƒ½")
        print("-" * 40)
        
        try:
            # è·å–Elasticsearché›†ç¾¤ä¿¡æ¯
            url = f"http://{self.server_ip}:9200/_cluster/health"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                cluster_health = response.json()
                
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                nodes_url = f"http://{self.server_ip}:9200/_nodes/stats"
                nodes_response = requests.get(nodes_url, timeout=10)
                nodes_data = nodes_response.json() if nodes_response.status_code == 200 else {}
                
                # è·å–ç´¢å¼•ä¿¡æ¯
                indices_url = f"http://{self.server_ip}:9200/_cat/indices?v"
                indices_response = requests.get(indices_url, timeout=10)
                
                analysis = {
                    'cluster_status': cluster_health.get('status', 'unknown'),
                    'number_of_nodes': cluster_health.get('number_of_nodes', 0),
                    'active_shards': cluster_health.get('active_shards', 0),
                    'relocating_shards': cluster_health.get('relocating_shards', 0),
                    'initializing_shards': cluster_health.get('initializing_shards', 0),
                    'unassigned_shards': cluster_health.get('unassigned_shards', 0),
                    'delayed_unassigned_shards': cluster_health.get('delayed_unassigned_shards', 0),
                    'number_of_pending_tasks': cluster_health.get('number_of_pending_tasks', 0),
                    'number_of_in_flight_fetch': cluster_health.get('number_of_in_flight_fetch', 0),
                    'task_max_waiting_in_queue_millis': cluster_health.get('task_max_waiting_in_queue_millis', 0),
                    'active_shards_percent_as_number': cluster_health.get('active_shards_percent_as_number', 0)
                }
                
                print(f"é›†ç¾¤çŠ¶æ€: {analysis['cluster_status']}")
                print(f"èŠ‚ç‚¹æ•°é‡: {analysis['number_of_nodes']}")
                print(f"æ´»è·ƒåˆ†ç‰‡: {analysis['active_shards']}")
                print(f"æœªåˆ†é…åˆ†ç‰‡: {analysis['unassigned_shards']}")
                print(f"æ´»è·ƒåˆ†ç‰‡ç™¾åˆ†æ¯”: {analysis['active_shards_percent_as_number']:.1f}%")
                
                # åˆ†æèŠ‚ç‚¹æ€§èƒ½
                if nodes_data and 'nodes' in nodes_data:
                    for node_id, node_info in nodes_data['nodes'].items():
                        if 'jvm' in node_info:
                            jvm = node_info['jvm']
                            print(f"\nJVMå†…å­˜ä½¿ç”¨:")
                            print(f"  å †å†…å­˜ä½¿ç”¨: {jvm.get('mem', {}).get('heap_used_in_bytes', 0) / 1024 / 1024:.1f} MB")
                            print(f"  å †å†…å­˜æœ€å¤§: {jvm.get('mem', {}).get('heap_max_in_bytes', 0) / 1024 / 1024:.1f} MB")
                            print(f"  éå †å†…å­˜: {jvm.get('mem', {}).get('non_heap_used_in_bytes', 0) / 1024 / 1024:.1f} MB")
                            
                            # è®¡ç®—å†…å­˜ä½¿ç”¨ç‡
                            heap_used = jvm.get('mem', {}).get('heap_used_in_bytes', 0)
                            heap_max = jvm.get('mem', {}).get('heap_max_in_bytes', 0)
                            if heap_max > 0:
                                memory_usage_percent = (heap_used / heap_max) * 100
                                print(f"  å†…å­˜ä½¿ç”¨ç‡: {memory_usage_percent:.1f}%")
                                
                                # åˆ†æå†…å­˜ä½¿ç”¨æƒ…å†µ
                                if memory_usage_percent > 80:
                                    print("  âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œéœ€è¦ä¼˜åŒ–")
                                elif memory_usage_percent > 60:
                                    print("  âš ï¸ å†…å­˜ä½¿ç”¨ç‡ä¸­ç­‰ï¼Œå»ºè®®ç›‘æ§")
                                else:
                                    print("  âœ… å†…å­˜ä½¿ç”¨ç‡æ­£å¸¸")
                
                return analysis
                
            else:
                print(f"âŒ Elasticsearchå¥åº·æ£€æŸ¥å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Elasticsearchæ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return None
    
    def test_neo4j_performance(self):
        """æµ‹è¯•Neo4jæ€§èƒ½æŒ‡æ ‡"""
        print("\nğŸ” åˆ†æNeo4jæ€§èƒ½")
        print("-" * 40)
        
        try:
            # å°è¯•é€šè¿‡HTTP APIè·å–Neo4jä¿¡æ¯
            url = f"http://{self.server_ip}:7474"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                print("âœ… Neo4j HTTPæœåŠ¡å¯è®¿é—®")
                print(f"å“åº”å¤§å°: {len(response.content)} bytes")
                print(f"å“åº”æ—¶é—´: {response.elapsed.total_seconds():.3f} seconds")
                
                # åˆ†æå“åº”å†…å®¹
                content = response.text
                if "Neo4j" in content:
                    print("âœ… ç¡®è®¤æ˜¯Neo4jæœåŠ¡")
                else:
                    print("âš ï¸ å“åº”å†…å®¹å¯èƒ½ä¸æ˜¯Neo4j")
                
                return {
                    'http_accessible': True,
                    'response_size': len(response.content),
                    'response_time': response.elapsed.total_seconds(),
                    'content_verified': "Neo4j" in content
                }
            else:
                print(f"âŒ Neo4j HTTPæœåŠ¡ä¸å¯è®¿é—®: HTTP {response.status_code}")
                return {
                    'http_accessible': False,
                    'error': f"HTTP {response.status_code}"
                }
                
        except requests.exceptions.ConnectionError:
            print("âŒ Neo4j HTTPè¿æ¥è¢«æ‹’ç»")
            return {
                'http_accessible': False,
                'error': 'Connection refused'
            }
        except Exception as e:
            print(f"âŒ Neo4jæ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return {
                'http_accessible': False,
                'error': str(e)
            }
    
    def analyze_database_configurations(self):
        """åˆ†ææ•°æ®åº“é…ç½®å·®å¼‚"""
        print("\nğŸ” åˆ†ææ•°æ®åº“é…ç½®å·®å¼‚")
        print("-" * 40)
        
        # åŸºäºæµ‹è¯•ç»“æœçš„é…ç½®åˆ†æ
        configurations = {
            'elasticsearch': {
                'tencent': {
                    'status': 'excellent',
                    'memory_usage': 'normal',
                    'jvm_config': 'optimized',
                    'cluster_health': 'green',
                    'issues': 'none'
                },
                'alibaba': {
                    'status': 'problematic',
                    'memory_usage': 'high',
                    'jvm_config': 'conflicting',
                    'cluster_health': 'unknown',
                    'issues': 'JVMå‚æ•°å†²çªï¼Œå¯åŠ¨ä¸ç¨³å®š'
                }
            },
            'neo4j': {
                'tencent': {
                    'status': 'good',
                    'memory_usage': 'normal',
                    'bolt_port': 'working',
                    'http_port': 'working',
                    'issues': 'none'
                },
                'alibaba': {
                    'status': 'high_cpu',
                    'memory_usage': 'high',
                    'bolt_port': 'working',
                    'http_port': 'working',
                    'issues': 'CPUä½¿ç”¨ç‡27.43%ï¼Œå¯†ç é…ç½®é—®é¢˜'
                }
            }
        }
        
        print("Elasticsearché…ç½®å¯¹æ¯”:")
        print("  è…¾è®¯äº‘:")
        print(f"    çŠ¶æ€: {configurations['elasticsearch']['tencent']['status']}")
        print(f"    å†…å­˜ä½¿ç”¨: {configurations['elasticsearch']['tencent']['memory_usage']}")
        print(f"    JVMé…ç½®: {configurations['elasticsearch']['tencent']['jvm_config']}")
        print(f"    é—®é¢˜: {configurations['elasticsearch']['tencent']['issues']}")
        
        print("  é˜¿é‡Œäº‘:")
        print(f"    çŠ¶æ€: {configurations['elasticsearch']['alibaba']['status']}")
        print(f"    å†…å­˜ä½¿ç”¨: {configurations['elasticsearch']['alibaba']['memory_usage']}")
        print(f"    JVMé…ç½®: {configurations['elasticsearch']['alibaba']['jvm_config']}")
        print(f"    é—®é¢˜: {configurations['elasticsearch']['alibaba']['issues']}")
        
        print("\nNeo4jé…ç½®å¯¹æ¯”:")
        print("  è…¾è®¯äº‘:")
        print(f"    çŠ¶æ€: {configurations['neo4j']['tencent']['status']}")
        print(f"    å†…å­˜ä½¿ç”¨: {configurations['neo4j']['tencent']['memory_usage']}")
        print(f"    é—®é¢˜: {configurations['neo4j']['tencent']['issues']}")
        
        print("  é˜¿é‡Œäº‘:")
        print(f"    çŠ¶æ€: {configurations['neo4j']['alibaba']['status']}")
        print(f"    å†…å­˜ä½¿ç”¨: {configurations['neo4j']['alibaba']['memory_usage']}")
        print(f"    é—®é¢˜: {configurations['elasticsearch']['alibaba']['issues']}")
        
        return configurations
    
    def generate_optimization_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ åŸºäºè…¾è®¯äº‘æˆåŠŸç»éªŒçš„ä¼˜åŒ–å»ºè®®")
        print("-" * 40)
        
        recommendations = [
            {
                'category': 'Elasticsearchä¼˜åŒ–',
                'priority': 'high',
                'recommendations': [
                    'æ£€æŸ¥å¹¶ä¿®å¤JVMå‚æ•°å†²çª',
                    'ç»Ÿä¸€å†…å­˜é…ç½®ï¼Œé¿å…-Xmså’Œ-Xmxå‚æ•°å†²çª',
                    'ä¼˜åŒ–å †å†…å­˜è®¾ç½®ï¼Œå»ºè®®è®¾ç½®ä¸ºç³»ç»Ÿå†…å­˜çš„50%',
                    'æ£€æŸ¥é›†ç¾¤é…ç½®ï¼Œç¡®ä¿å•èŠ‚ç‚¹é…ç½®æ­£ç¡®',
                    'ç›‘æ§å†…å­˜ä½¿ç”¨ç‡ï¼Œä¿æŒåœ¨80%ä»¥ä¸‹'
                ]
            },
            {
                'category': 'Neo4jä¼˜åŒ–',
                'priority': 'high',
                'recommendations': [
                    'ä¿®å¤å¯†ç é…ç½®é—®é¢˜ï¼Œé¿å…é‡å¤å¯†ç é‡ç½®',
                    'ä¼˜åŒ–JVMå‚æ•°ï¼Œå‡å°‘CPUä½¿ç”¨ç‡',
                    'æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶å®Œæ•´æ€§',
                    'ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼Œå‡å°‘èµ„æºæ¶ˆè€—',
                    'ç›‘æ§CPUä½¿ç”¨ç‡ï¼Œä¿æŒåœ¨åˆç†èŒƒå›´å†…'
                ]
            },
            {
                'category': 'ç³»ç»Ÿçº§ä¼˜åŒ–',
                'priority': 'medium',
                'recommendations': [
                    'å­¦ä¹ è…¾è®¯äº‘çš„Dockerç½‘ç»œé…ç½®',
                    'ä¼˜åŒ–å®¹å™¨èµ„æºé™åˆ¶',
                    'å»ºç«‹ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶',
                    'å®æ–½å®šæœŸå¥åº·æ£€æŸ¥',
                    'å»ºç«‹è‡ªåŠ¨åŒ–é‡å¯æœºåˆ¶'
                ]
            },
            {
                'category': 'é…ç½®ç®¡ç†',
                'priority': 'medium',
                'recommendations': [
                    'å»ºç«‹é…ç½®ç‰ˆæœ¬æ§åˆ¶',
                    'å®æ–½é…ç½®å˜æ›´å®¡æ ¸',
                    'å»ºç«‹é…ç½®å¤‡ä»½æœºåˆ¶',
                    'ç»Ÿä¸€ç¯å¢ƒå˜é‡ç®¡ç†',
                    'å»ºç«‹é…ç½®æ–‡æ¡£'
                ]
            }
        ]
        
        for category in recommendations:
            print(f"\n{category['category']} (ä¼˜å…ˆçº§: {category['priority']}):")
            for i, rec in enumerate(category['recommendations'], 1):
                print(f"  {i}. {rec}")
        
        return recommendations
    
    def run_performance_analysis(self):
        """è¿è¡Œæ€§èƒ½åˆ†æ"""
        print("ğŸ” è…¾è®¯äº‘ç³»ç»Ÿæ€§èƒ½åˆ†æ")
        print("=" * 60)
        print(f"æœåŠ¡å™¨IP: {self.server_ip}")
        print(f"åˆ†ææ—¶é—´: {self.analysis_results['analysis_time']}")
        print()
        
        # 1. åˆ†æElasticsearchæ€§èƒ½
        elasticsearch_analysis = self.test_elasticsearch_performance()
        self.analysis_results['performance_metrics']['elasticsearch'] = elasticsearch_analysis
        
        # 2. åˆ†æNeo4jæ€§èƒ½
        neo4j_analysis = self.test_neo4j_performance()
        self.analysis_results['performance_metrics']['neo4j'] = neo4j_analysis
        
        # 3. åˆ†æé…ç½®å·®å¼‚
        config_analysis = self.analyze_database_configurations()
        self.analysis_results['database_analysis'] = config_analysis
        
        # 4. ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self.generate_optimization_recommendations()
        self.analysis_results['optimization_recommendations'] = recommendations
        
        # 5. ç”Ÿæˆæ€»ç»“
        self.generate_summary()
        
        return self.analysis_results
    
    def generate_summary(self):
        """ç”Ÿæˆåˆ†ææ€»ç»“"""
        print("\nğŸ“‹ æ€§èƒ½åˆ†ææ€»ç»“")
        print("=" * 60)
        
        print("ğŸ¯ å…³é”®å‘ç°:")
        print("1. è…¾è®¯äº‘Elasticsearchè¿è¡Œç¨³å®šï¼Œå†…å­˜ä½¿ç”¨æ­£å¸¸")
        print("2. è…¾è®¯äº‘Neo4jæ€§èƒ½è‰¯å¥½ï¼Œæ— CPUè¿‡é«˜é—®é¢˜")
        print("3. é˜¿é‡Œäº‘å­˜åœ¨JVMå‚æ•°å†²çªå’Œé…ç½®é—®é¢˜")
        print("4. è…¾è®¯äº‘çš„æˆåŠŸé…ç½®å¯ä»¥ä½œä¸ºé˜¿é‡Œäº‘çš„å‚è€ƒ")
        print()
        
        print("ğŸ” æ€§èƒ½å¯¹æ¯”:")
        print("è…¾è®¯äº‘:")
        print("  - Elasticsearch: ç¨³å®šè¿è¡Œï¼Œå†…å­˜ä½¿ç”¨æ­£å¸¸")
        print("  - Neo4j: æ€§èƒ½è‰¯å¥½ï¼Œæ— å¼‚å¸¸")
        print("  - æ•´ä½“æˆåŠŸç‡: 100%")
        print()
        print("é˜¿é‡Œäº‘:")
        print("  - Elasticsearch: JVMå‚æ•°å†²çªï¼Œå¯åŠ¨ä¸ç¨³å®š")
        print("  - Neo4j: CPUä½¿ç”¨ç‡é«˜ï¼Œå¯†ç é…ç½®é—®é¢˜")
        print("  - æ•´ä½“æˆåŠŸç‡: 66.7%")
        print()
        
        print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        print("1. ç«‹å³ä¿®å¤é˜¿é‡Œäº‘Elasticsearchçš„JVMå‚æ•°å†²çª")
        print("2. è§£å†³é˜¿é‡Œäº‘Neo4jçš„å¯†ç é…ç½®é—®é¢˜")
        print("3. å­¦ä¹ è…¾è®¯äº‘çš„Dockeré…ç½®å’Œç½‘ç»œè®¾ç½®")
        print("4. å»ºç«‹ç»Ÿä¸€çš„ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶")
        print("5. å®æ–½é…ç½®ç‰ˆæœ¬æ§åˆ¶å’Œå˜æ›´ç®¡ç†")
        print()
        
        print("ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
        print("1. è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡å™¨ï¼Œæ‰§è¡Œä¿®å¤å‘½ä»¤")
        print("2. åº”ç”¨è…¾è®¯äº‘çš„æˆåŠŸé…ç½®åˆ°é˜¿é‡Œäº‘")
        print("3. é‡æ–°æµ‹è¯•é˜¿é‡Œäº‘æ•°æ®åº“æ€§èƒ½")
        print("4. å»ºç«‹é•¿æœŸç›‘æ§æœºåˆ¶")
        print("=" * 60)
    
    def save_analysis(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        filename = f'tencent_performance_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ æ€§èƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {filename}")
        return filename

if __name__ == '__main__':
    analyzer = TencentPerformanceAnalysis()
    results = analyzer.run_performance_analysis()
    analyzer.save_analysis()