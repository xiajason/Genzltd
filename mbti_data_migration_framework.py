#!/usr/bin/env python3
"""
MBTIæ•°æ®è¿ç§»å’Œæ›´æ–°æ¡†æ¶
åˆ›å»ºæ—¶é—´: 2025å¹´10æœˆ4æ—¥
ç‰ˆæœ¬: v1.0 (æ•°æ®è¿ç§»ç‰ˆ)
åŸºäº: MBTIæ„Ÿæ€§AIèº«ä»½ç»Ÿä¸€å®æ–½è®¡åˆ’
ç›®æ ‡: å®ç°å®Œæ•´çš„æ•°æ®è¿ç§»ã€æ›´æ–°å’Œä¸€è‡´æ€§æ£€æŸ¥
"""

import json
import asyncio
import sqlite3
import mysql.connector
import psycopg2
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
from enum import Enum
import hashlib
import os


# ==================== æ•°æ®æ¨¡å‹ ====================

class MigrationStatus(Enum):
    """è¿ç§»çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"


@dataclass
class MigrationRecord:
    """è¿ç§»è®°å½•"""
    migration_id: str
    version: str
    description: str
    status: MigrationStatus
    created_at: datetime
    completed_at: Optional[datetime]
    rollback_at: Optional[datetime]
    checksum: str
    execution_time: float
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['status'] = self.status.value
        result['created_at'] = self.created_at.isoformat()
        result['completed_at'] = self.completed_at.isoformat() if self.completed_at else None
        result['rollback_at'] = self.rollback_at.isoformat() if self.rollback_at else None
        return result


@dataclass
class DataConsistencyCheck:
    """æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥"""
    check_id: str
    check_name: str
    table_name: str
    check_type: str  # count, integrity, foreign_key, data_type
    expected_value: Any
    actual_value: Any
    status: str  # passed, failed, warning
    message: str
    timestamp: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['timestamp'] = self.timestamp.isoformat()
        return result


# ==================== æ•°æ®è¿ç§»æ¡†æ¶ ====================

class MBTIDataMigrationFramework:
    """MBTIæ•°æ®è¿ç§»å’Œæ›´æ–°æ¡†æ¶"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.setup_logging()
        
        # æ•°æ®åº“è¿æ¥
        self.connections = {}
        self.migration_history = []
        
        # è¿ç§»ç‰ˆæœ¬ç®¡ç†
        self.current_version = "1.0.0"
        self.target_version = "1.1.0"
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ
        self.consistency_checks = []
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
    
    async def initialize_connections(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        self.logger.info("ğŸ”Œ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
        
        # MySQLè¿æ¥
        if "mysql" in self.config:
            try:
                self.connections["mysql"] = mysql.connector.connect(
                    host=self.config["mysql"]["host"],
                    user=self.config["mysql"]["user"],
                    password=self.config["mysql"]["password"],
                    database=self.config["mysql"]["database"],
                    charset="utf8mb4"
                )
                self.logger.info("âœ… MySQLè¿æ¥æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ MySQLè¿æ¥å¤±è´¥: {str(e)}")
        
        # PostgreSQLè¿æ¥
        if "postgresql" in self.config:
            try:
                self.connections["postgresql"] = psycopg2.connect(
                    host=self.config["postgresql"]["host"],
                    user=self.config["postgresql"]["user"],
                    password=self.config["postgresql"]["password"],
                    database=self.config["postgresql"]["database"]
                )
                self.logger.info("âœ… PostgreSQLè¿æ¥æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ PostgreSQLè¿æ¥å¤±è´¥: {str(e)}")
        
        # SQLiteè¿æ¥
        if "sqlite" in self.config:
            try:
                self.connections["sqlite"] = sqlite3.connect(
                    self.config["sqlite"]["database"]
                )
                self.logger.info("âœ… SQLiteè¿æ¥æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ SQLiteè¿æ¥å¤±è´¥: {str(e)}")
    
    async def create_migration_tables(self):
        """åˆ›å»ºè¿ç§»ç®¡ç†è¡¨"""
        self.logger.info("ğŸ“‹ åˆ›å»ºè¿ç§»ç®¡ç†è¡¨")
        
        migration_table_sql = """
        CREATE TABLE IF NOT EXISTS mbti_migrations (
            id VARCHAR(255) PRIMARY KEY,
            version VARCHAR(50) NOT NULL,
            description TEXT,
            status VARCHAR(20) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            completed_at TIMESTAMP NULL,
            rollback_at TIMESTAMP NULL,
            checksum VARCHAR(64) NOT NULL,
            execution_time FLOAT DEFAULT 0.0
        );
        """
        
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute(migration_table_sql)
                connection.commit()
                self.logger.info(f"âœ… {db_type} è¿ç§»ç®¡ç†è¡¨åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ {db_type} è¿ç§»ç®¡ç†è¡¨åˆ›å»ºå¤±è´¥: {str(e)}")
    
    async def run_migration(self, migration_id: str, version: str, description: str, 
                          migration_sql: str, rollback_sql: str = None) -> MigrationRecord:
        """è¿è¡Œæ•°æ®è¿ç§»"""
        start_time = datetime.now()
        
        self.logger.info(f"ğŸš€ å¼€å§‹è¿ç§»: {migration_id} - {description}")
        
        # è®¡ç®—è¿ç§»SQLçš„æ ¡éªŒå’Œ
        checksum = hashlib.sha256(migration_sql.encode()).hexdigest()
        
        # åˆ›å»ºè¿ç§»è®°å½•
        migration_record = MigrationRecord(
            migration_id=migration_id,
            version=version,
            description=description,
            status=MigrationStatus.RUNNING,
            created_at=start_time,
            completed_at=None,
            rollback_at=None,
            checksum=checksum,
            execution_time=0.0
        )
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»è¿è¡Œè¿‡æ­¤è¿ç§»
            if await self.is_migration_completed(migration_id):
                self.logger.warning(f"âš ï¸ è¿ç§» {migration_id} å·²ç»å®Œæˆï¼Œè·³è¿‡")
                migration_record.status = MigrationStatus.COMPLETED
                migration_record.completed_at = datetime.now()
                return migration_record
            
            # æ‰§è¡Œè¿ç§»SQL
            for db_type, connection in self.connections.items():
                try:
                    cursor = connection.cursor()
                    cursor.execute(migration_sql)
                    connection.commit()
                    self.logger.info(f"âœ… {db_type} è¿ç§»æ‰§è¡ŒæˆåŠŸ")
                except Exception as e:
                    self.logger.error(f"âŒ {db_type} è¿ç§»æ‰§è¡Œå¤±è´¥: {str(e)}")
                    # å¦‚æœæ”¯æŒå›æ»šï¼Œæ‰§è¡Œå›æ»š
                    if rollback_sql:
                        try:
                            cursor.execute(rollback_sql)
                            connection.commit()
                            self.logger.info(f"âœ… {db_type} å›æ»šæ‰§è¡ŒæˆåŠŸ")
                        except Exception as rollback_error:
                            self.logger.error(f"âŒ {db_type} å›æ»šæ‰§è¡Œå¤±è´¥: {str(rollback_error)}")
                    raise e
            
            # è®°å½•è¿ç§»å®Œæˆ
            migration_record.status = MigrationStatus.COMPLETED
            migration_record.completed_at = datetime.now()
            migration_record.execution_time = (datetime.now() - start_time).total_seconds()
            
            # ä¿å­˜è¿ç§»è®°å½•åˆ°æ•°æ®åº“
            await self.save_migration_record(migration_record)
            
            self.logger.info(f"âœ… è¿ç§» {migration_id} å®Œæˆï¼Œè€—æ—¶ {migration_record.execution_time:.2f}ç§’")
            
        except Exception as e:
            migration_record.status = MigrationStatus.FAILED
            migration_record.execution_time = (datetime.now() - start_time).total_seconds()
            self.logger.error(f"âŒ è¿ç§» {migration_id} å¤±è´¥: {str(e)}")
            raise e
        
        return migration_record
    
    async def is_migration_completed(self, migration_id: str) -> bool:
        """æ£€æŸ¥è¿ç§»æ˜¯å¦å·²å®Œæˆ"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute(
                    "SELECT COUNT(*) FROM mbti_migrations WHERE id = %s AND status = 'completed'",
                    (migration_id,)
                )
                result = cursor.fetchone()
                if result and result[0] > 0:
                    return True
            except Exception as e:
                self.logger.error(f"âŒ {db_type} æ£€æŸ¥è¿ç§»çŠ¶æ€å¤±è´¥: {str(e)}")
        return False
    
    async def save_migration_record(self, migration_record: MigrationRecord):
        """ä¿å­˜è¿ç§»è®°å½•"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("""
                    INSERT INTO mbti_migrations 
                    (id, version, description, status, created_at, completed_at, rollback_at, checksum, execution_time)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                    status = VALUES(status),
                    completed_at = VALUES(completed_at),
                    rollback_at = VALUES(rollback_at),
                    execution_time = VALUES(execution_time)
                """, (
                    migration_record.migration_id,
                    migration_record.version,
                    migration_record.description,
                    migration_record.status.value,
                    migration_record.created_at,
                    migration_record.completed_at,
                    migration_record.rollback_at,
                    migration_record.checksum,
                    migration_record.execution_time
                ))
                connection.commit()
                self.logger.info(f"âœ… {db_type} è¿ç§»è®°å½•ä¿å­˜æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ {db_type} è¿ç§»è®°å½•ä¿å­˜å¤±è´¥: {str(e)}")
    
    async def check_data_consistency(self) -> List[DataConsistencyCheck]:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        self.logger.info("ğŸ” å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        
        consistency_checks = []
        
        # æ£€æŸ¥MBTIç±»å‹è¡¨
        await self.check_mbti_types_consistency(consistency_checks)
        
        # æ£€æŸ¥èŠ±å‰ä¿¡æ¯è¡¨
        await self.check_flowers_consistency(consistency_checks)
        
        # æ£€æŸ¥MBTI-èŠ±å‰æ˜ å°„è¡¨
        await self.check_mbti_flower_mappings_consistency(consistency_checks)
        
        # æ£€æŸ¥å…¼å®¹æ€§çŸ©é˜µè¡¨
        await self.check_compatibility_matrix_consistency(consistency_checks)
        
        # æ£€æŸ¥èŒä¸šä¿¡æ¯è¡¨
        await self.check_careers_consistency(consistency_checks)
        
        # æ£€æŸ¥APIé…ç½®è¡¨
        await self.check_api_configs_consistency(consistency_checks)
        
        self.consistency_checks = consistency_checks
        return consistency_checks
    
    async def check_mbti_types_consistency(self, checks: List[DataConsistencyCheck]):
        """æ£€æŸ¥MBTIç±»å‹è¡¨ä¸€è‡´æ€§"""
        expected_mbti_types = [
            "INTJ", "INTP", "ENTJ", "ENTP", "INFJ", "INFP", "ENFJ", "ENFP",
            "ISTJ", "ISFJ", "ESTJ", "ESFJ", "ISTP", "ISFP", "ESTP", "ESFP"
        ]
        
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT COUNT(*) FROM mbti_types")
                actual_count = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"mbti_types_count_{db_type}",
                    check_name="MBTIç±»å‹æ•°é‡æ£€æŸ¥",
                    table_name="mbti_types",
                    check_type="count",
                    expected_value=16,
                    actual_value=actual_count,
                    status="passed" if actual_count == 16 else "failed",
                    message=f"MBTIç±»å‹æ•°é‡: æœŸæœ›16ï¼Œå®é™…{actual_count}",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
                # æ£€æŸ¥æ¯ä¸ªMBTIç±»å‹æ˜¯å¦å­˜åœ¨
                for mbti_type in expected_mbti_types:
                    cursor.execute("SELECT COUNT(*) FROM mbti_types WHERE type_code = %s", (mbti_type,))
                    exists = cursor.fetchone()[0] > 0
                    
                    check = DataConsistencyCheck(
                        check_id=f"mbti_type_exists_{mbti_type}_{db_type}",
                        check_name=f"MBTIç±»å‹ {mbti_type} å­˜åœ¨æ€§æ£€æŸ¥",
                        table_name="mbti_types",
                        check_type="integrity",
                        expected_value=True,
                        actual_value=exists,
                        status="passed" if exists else "failed",
                        message=f"MBTIç±»å‹ {mbti_type}: {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}",
                        timestamp=datetime.now()
                    )
                    checks.append(check)
                    
            except Exception as e:
                check = DataConsistencyCheck(
                    check_id=f"mbti_types_error_{db_type}",
                    check_name="MBTIç±»å‹è¡¨æ£€æŸ¥é”™è¯¯",
                    table_name="mbti_types",
                    check_type="error",
                    expected_value=None,
                    actual_value=None,
                    status="failed",
                    message=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                    timestamp=datetime.now()
                )
                checks.append(check)
    
    async def check_flowers_consistency(self, checks: List[DataConsistencyCheck]):
        """æ£€æŸ¥èŠ±å‰ä¿¡æ¯è¡¨ä¸€è‡´æ€§"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT COUNT(*) FROM flowers")
                actual_count = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"flowers_count_{db_type}",
                    check_name="èŠ±å‰æ•°é‡æ£€æŸ¥",
                    table_name="flowers",
                    check_type="count",
                    expected_value=">0",
                    actual_value=actual_count,
                    status="passed" if actual_count > 0 else "failed",
                    message=f"èŠ±å‰æ•°é‡: {actual_count}",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
                # æ£€æŸ¥èŠ±å‰ä¿¡æ¯å®Œæ•´æ€§
                cursor.execute("SELECT COUNT(*) FROM flowers WHERE name IS NULL OR name = ''")
                null_names = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"flowers_integrity_{db_type}",
                    check_name="èŠ±å‰ä¿¡æ¯å®Œæ•´æ€§æ£€æŸ¥",
                    table_name="flowers",
                    check_type="integrity",
                    expected_value=0,
                    actual_value=null_names,
                    status="passed" if null_names == 0 else "failed",
                    message=f"èŠ±å‰åç§°å®Œæ•´æ€§: {null_names}ä¸ªç©ºåç§°",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
            except Exception as e:
                check = DataConsistencyCheck(
                    check_id=f"flowers_error_{db_type}",
                    check_name="èŠ±å‰ä¿¡æ¯è¡¨æ£€æŸ¥é”™è¯¯",
                    table_name="flowers",
                    check_type="error",
                    expected_value=None,
                    actual_value=None,
                    status="failed",
                    message=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                    timestamp=datetime.now()
                )
                checks.append(check)
    
    async def check_mbti_flower_mappings_consistency(self, checks: List[DataConsistencyCheck]):
        """æ£€æŸ¥MBTI-èŠ±å‰æ˜ å°„è¡¨ä¸€è‡´æ€§"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT COUNT(*) FROM mbti_flower_mappings")
                actual_count = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"mbti_flower_mappings_count_{db_type}",
                    check_name="MBTI-èŠ±å‰æ˜ å°„æ•°é‡æ£€æŸ¥",
                    table_name="mbti_flower_mappings",
                    check_type="count",
                    expected_value=">0",
                    actual_value=actual_count,
                    status="passed" if actual_count > 0 else "failed",
                    message=f"MBTI-èŠ±å‰æ˜ å°„æ•°é‡: {actual_count}",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
                # æ£€æŸ¥å¤–é”®çº¦æŸ
                cursor.execute("""
                    SELECT COUNT(*) FROM mbti_flower_mappings mfm
                    LEFT JOIN mbti_types mt ON mfm.mbti_type_id = mt.id
                    LEFT JOIN flowers f ON mfm.flower_id = f.id
                    WHERE mt.id IS NULL OR f.id IS NULL
                """)
                invalid_foreign_keys = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"mbti_flower_mappings_fk_{db_type}",
                    check_name="MBTI-èŠ±å‰æ˜ å°„å¤–é”®æ£€æŸ¥",
                    table_name="mbti_flower_mappings",
                    check_type="foreign_key",
                    expected_value=0,
                    actual_value=invalid_foreign_keys,
                    status="passed" if invalid_foreign_keys == 0 else "failed",
                    message=f"æ— æ•ˆå¤–é”®: {invalid_foreign_keys}ä¸ª",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
            except Exception as e:
                check = DataConsistencyCheck(
                    check_id=f"mbti_flower_mappings_error_{db_type}",
                    check_name="MBTI-èŠ±å‰æ˜ å°„è¡¨æ£€æŸ¥é”™è¯¯",
                    table_name="mbti_flower_mappings",
                    check_type="error",
                    expected_value=None,
                    actual_value=None,
                    status="failed",
                    message=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                    timestamp=datetime.now()
                )
                checks.append(check)
    
    async def check_compatibility_matrix_consistency(self, checks: List[DataConsistencyCheck]):
        """æ£€æŸ¥å…¼å®¹æ€§çŸ©é˜µè¡¨ä¸€è‡´æ€§"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT COUNT(*) FROM mbti_compatibility_matrix")
                actual_count = cursor.fetchone()[0]
                
                # æœŸæœ›çš„å…¼å®¹æ€§çŸ©é˜µæ•°é‡ (16x16 = 256)
                expected_count = 16 * 16
                
                check = DataConsistencyCheck(
                    check_id=f"compatibility_matrix_count_{db_type}",
                    check_name="å…¼å®¹æ€§çŸ©é˜µæ•°é‡æ£€æŸ¥",
                    table_name="mbti_compatibility_matrix",
                    check_type="count",
                    expected_value=expected_count,
                    actual_value=actual_count,
                    status="passed" if actual_count == expected_count else "failed",
                    message=f"å…¼å®¹æ€§çŸ©é˜µæ•°é‡: æœŸæœ›{expected_count}ï¼Œå®é™…{actual_count}",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
            except Exception as e:
                check = DataConsistencyCheck(
                    check_id=f"compatibility_matrix_error_{db_type}",
                    check_name="å…¼å®¹æ€§çŸ©é˜µè¡¨æ£€æŸ¥é”™è¯¯",
                    table_name="mbti_compatibility_matrix",
                    check_type="error",
                    expected_value=None,
                    actual_value=None,
                    status="failed",
                    message=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                    timestamp=datetime.now()
                )
                checks.append(check)
    
    async def check_careers_consistency(self, checks: List[DataConsistencyCheck]):
        """æ£€æŸ¥èŒä¸šä¿¡æ¯è¡¨ä¸€è‡´æ€§"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT COUNT(*) FROM careers")
                actual_count = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"careers_count_{db_type}",
                    check_name="èŒä¸šæ•°é‡æ£€æŸ¥",
                    table_name="careers",
                    check_type="count",
                    expected_value=">0",
                    actual_value=actual_count,
                    status="passed" if actual_count > 0 else "failed",
                    message=f"èŒä¸šæ•°é‡: {actual_count}",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
            except Exception as e:
                check = DataConsistencyCheck(
                    check_id=f"careers_error_{db_type}",
                    check_name="èŒä¸šä¿¡æ¯è¡¨æ£€æŸ¥é”™è¯¯",
                    table_name="careers",
                    check_type="error",
                    expected_value=None,
                    actual_value=None,
                    status="failed",
                    message=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                    timestamp=datetime.now()
                )
                checks.append(check)
    
    async def check_api_configs_consistency(self, checks: List[DataConsistencyCheck]):
        """æ£€æŸ¥APIé…ç½®è¡¨ä¸€è‡´æ€§"""
        for db_type, connection in self.connections.items():
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT COUNT(*) FROM api_service_configs")
                actual_count = cursor.fetchone()[0]
                
                check = DataConsistencyCheck(
                    check_id=f"api_configs_count_{db_type}",
                    check_name="APIé…ç½®æ•°é‡æ£€æŸ¥",
                    table_name="api_service_configs",
                    check_type="count",
                    expected_value=">=0",
                    actual_value=actual_count,
                    status="passed",
                    message=f"APIé…ç½®æ•°é‡: {actual_count}",
                    timestamp=datetime.now()
                )
                checks.append(check)
                
            except Exception as e:
                check = DataConsistencyCheck(
                    check_id=f"api_configs_error_{db_type}",
                    check_name="APIé…ç½®è¡¨æ£€æŸ¥é”™è¯¯",
                    table_name="api_service_configs",
                    check_type="error",
                    expected_value=None,
                    actual_value=None,
                    status="failed",
                    message=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                    timestamp=datetime.now()
                )
                checks.append(check)
    
    async def generate_migration_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        total_checks = len(self.consistency_checks)
        passed_checks = len([c for c in self.consistency_checks if c.status == "passed"])
        failed_checks = len([c for c in self.consistency_checks if c.status == "failed"])
        
        success_rate = (passed_checks / total_checks * 100) if total_checks > 0 else 0
        
        report = {
            "migration_summary": {
                "total_checks": total_checks,
                "passed_checks": passed_checks,
                "failed_checks": failed_checks,
                "success_rate": success_rate,
                "timestamp": datetime.now().isoformat()
            },
            "consistency_checks": [check.to_dict() for check in self.consistency_checks],
            "recommendations": self.generate_recommendations(),
            "next_steps": self.generate_next_steps()
        }
        
        return report
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        failed_checks = [c for c in self.consistency_checks if c.status == "failed"]
        
        if failed_checks:
            recommendations.append("ğŸ”§ ä¿®å¤æ•°æ®ä¸€è‡´æ€§é—®é¢˜")
            recommendations.append("ğŸ“Š å®Œå–„ç¼ºå¤±çš„æ•°æ®")
            recommendations.append("ğŸ” æ£€æŸ¥å¤–é”®çº¦æŸ")
            recommendations.append("ğŸ“ˆ ä¼˜åŒ–æ•°æ®è´¨é‡")
        else:
            recommendations.append("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
            recommendations.append("ğŸš€ å¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µå¼€å‘")
            recommendations.append("ğŸ“ˆ è€ƒè™‘æ€§èƒ½ä¼˜åŒ–")
            recommendations.append("ğŸ” å®šæœŸè¿›è¡Œæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        
        return recommendations
    
    def generate_next_steps(self) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        next_steps = []
        
        failed_checks = [c for c in self.consistency_checks if c.status == "failed"]
        
        if failed_checks:
            next_steps.append("1. ä¿®å¤æ•°æ®ä¸€è‡´æ€§é—®é¢˜")
            next_steps.append("2. é‡æ–°è¿è¡Œæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
            next_steps.append("3. éªŒè¯ä¿®å¤ç»“æœ")
        else:
            next_steps.append("1. å¼€å§‹Week 2: APIç½‘å…³å’Œè®¤è¯ç³»ç»Ÿå»ºè®¾")
            next_steps.append("2. é›†æˆæ•°æ®è¿ç§»æ¡†æ¶")
            next_steps.append("3. å¼€å‘ç”¨æˆ·ç•Œé¢")
            next_steps.append("4. è¿›è¡Œé›†æˆæµ‹è¯•")
        
        return next_steps
    
    async def close_connections(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        for db_type, connection in self.connections.items():
            try:
                connection.close()
                self.logger.info(f"âœ… {db_type} è¿æ¥å·²å…³é—­")
            except Exception as e:
                self.logger.error(f"âŒ {db_type} è¿æ¥å…³é—­å¤±è´¥: {str(e)}")


# ==================== ä¸»å‡½æ•°å’Œç¤ºä¾‹ ====================

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ MBTIæ•°æ®è¿ç§»å’Œæ›´æ–°æ¡†æ¶")
    print("ç‰ˆæœ¬: v1.0 (æ•°æ®è¿ç§»ç‰ˆ)")
    print("åŸºäº: MBTIæ„Ÿæ€§AIèº«ä»½ç»Ÿä¸€å®æ–½è®¡åˆ’")
    print("=" * 60)
    
    # æ•°æ®åº“é…ç½®
    config = {
        "mysql": {
            "host": "localhost",
            "user": "root",
            "password": "password",
            "database": "mbti_db"
        },
        "postgresql": {
            "host": "localhost",
            "user": "postgres",
            "password": "password",
            "database": "mbti_db"
        },
        "sqlite": {
            "database": "mbti.db"
        }
    }
    
    # åˆå§‹åŒ–è¿ç§»æ¡†æ¶
    migration_framework = MBTIDataMigrationFramework(config)
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        await migration_framework.initialize_connections()
        
        # åˆ›å»ºè¿ç§»ç®¡ç†è¡¨
        await migration_framework.create_migration_tables()
        
        # è¿è¡Œæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        print("\nğŸ” å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥...")
        consistency_checks = await migration_framework.check_data_consistency()
        
        # ç”Ÿæˆè¿ç§»æŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")
        migration_report = await migration_framework.generate_migration_report()
        
        # è¾“å‡ºæ£€æŸ¥ç»“æœ
        print("\nğŸ“‹ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ")
        print(f"æ€»æ£€æŸ¥æ•°: {migration_report['migration_summary']['total_checks']}")
        print(f"é€šè¿‡æ£€æŸ¥: {migration_report['migration_summary']['passed_checks']}")
        print(f"å¤±è´¥æ£€æŸ¥: {migration_report['migration_summary']['failed_checks']}")
        print(f"æˆåŠŸç‡: {migration_report['migration_summary']['success_rate']:.1f}%")
        
        # è¾“å‡ºè¯¦ç»†ç»“æœ
        print("\nğŸ“‹ è¯¦ç»†æ£€æŸ¥ç»“æœ")
        for check in migration_report['consistency_checks']:
            status_icon = "âœ…" if check['status'] == 'passed' else "âŒ"
            print(f"{status_icon} {check['check_name']}: {check['message']}")
        
        # è¾“å‡ºå»ºè®®
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®")
        for recommendation in migration_report['recommendations']:
            print(f"  {recommendation}")
        
        # è¾“å‡ºä¸‹ä¸€æ­¥è¡ŒåŠ¨
        print("\nğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨")
        for step in migration_report['next_steps']:
            print(f"  {step}")
        
        # ä¿å­˜è¿ç§»æŠ¥å‘Š
        with open('mbti_data_migration_report.json', 'w', encoding='utf-8') as f:
            json.dump(migration_report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¿ç§»æŠ¥å‘Šå·²ä¿å­˜åˆ°: mbti_data_migration_report.json")
        
    except Exception as e:
        print(f"âŒ è¿ç§»æ¡†æ¶æ‰§è¡Œå¤±è´¥: {str(e)}")
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        await migration_framework.close_connections()
    
    print("\nğŸ‰ MBTIæ•°æ®è¿ç§»å’Œæ›´æ–°æ¡†æ¶æ‰§è¡Œå®Œæˆï¼")
    print("ğŸ“‹ æ”¯æŒçš„åŠŸèƒ½:")
    print("  - æ•°æ®åº“è¿æ¥ç®¡ç†")
    print("  - è¿ç§»ç‰ˆæœ¬ç®¡ç†")
    print("  - æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
    print("  - è¿ç§»è®°å½•ç®¡ç†")
    print("  - å›æ»šæ”¯æŒ")
    print("  - å¤šæ•°æ®åº“æ”¯æŒ")


if __name__ == "__main__":
    asyncio.run(main())
