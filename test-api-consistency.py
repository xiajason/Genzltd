#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
APIæ•°æ®ä¸€è‡´æ€§æµ‹è¯•è„šæœ¬
åŸºäºä¸‰ç¯å¢ƒæ¶æ„çš„APIæ•°æ®ä¸€è‡´æ€§éªŒè¯
"""

import requests
import json
import time
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import concurrent.futures
from dataclasses import dataclass

@dataclass
class APIEndpoint:
    path: str
    method: str = 'GET'
    expected_status: int = 200
    timeout: int = 10
    description: str = ""

class APIConsistencyTester:
    def __init__(self):
        self.environments = {
            'local': {
                'base_url': 'http://localhost:3000',
                'name': 'æœ¬åœ°å¼€å‘ç¯å¢ƒ',
                'timeout': 5
            },
            'tencent': {
                'base_url': 'http://101.33.251.158:9200',
                'name': 'è…¾è®¯äº‘æµ‹è¯•ç¯å¢ƒ',
                'timeout': 10
            },
            'alibaba': {
                'base_url': 'http://47.115.168.107:9200',
                'name': 'é˜¿é‡Œäº‘ç”Ÿäº§ç¯å¢ƒ',
                'timeout': 10
            }
        }
        
        self.test_endpoints = [
            APIEndpoint('/api/health', 'GET', 200, 5, 'å¥åº·æ£€æŸ¥'),
            APIEndpoint('/api/trpc/daoConfig.getDAOTypes', 'GET', 200, 5, 'DAOç±»å‹è·å–'),
            APIEndpoint('/api/users', 'GET', 200, 5, 'ç”¨æˆ·åˆ—è¡¨'),
            APIEndpoint('/api/dao/configs', 'GET', 200, 5, 'DAOé…ç½®åˆ—è¡¨'),
            APIEndpoint('/api/dao/settings', 'GET', 200, 5, 'DAOè®¾ç½®åˆ—è¡¨'),
        ]
        
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'environments': {},
            'comparisons': {},
            'summary': {}
        }

    def make_request(self, env_name: str, endpoint: APIEndpoint) -> Dict[str, Any]:
        """å‘é€APIè¯·æ±‚"""
        env = self.environments[env_name]
        url = f"{env['base_url']}{endpoint.path}"
        
        try:
            response = requests.request(
                method=endpoint.method,
                url=url,
                timeout=endpoint.timeout
            )
            
            return {
                'success': True,
                'status_code': response.status_code,
                'response_time': response.elapsed.total_seconds(),
                'content_type': response.headers.get('content-type', ''),
                'content_length': len(response.content),
                'data': response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text[:1000],
                'headers': dict(response.headers),
                'url': url,
                'timestamp': datetime.now().isoformat()
            }
        except requests.exceptions.Timeout:
            return {
                'success': False,
                'error': 'Timeout',
                'url': url,
                'timestamp': datetime.now().isoformat()
            }
        except requests.exceptions.ConnectionError:
            return {
                'success': False,
                'error': 'Connection Error',
                'url': url,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'url': url,
                'timestamp': datetime.now().isoformat()
            }

    def test_environment_apis(self, env_name: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªç¯å¢ƒçš„æ‰€æœ‰API"""
        print(f"ğŸ” æµ‹è¯• {self.environments[env_name]['name']} API...")
        
        env_results = {
            'environment': env_name,
            'base_url': self.environments[env_name]['base_url'],
            'endpoints': {},
            'summary': {
                'total_endpoints': len(self.test_endpoints),
                'successful_requests': 0,
                'failed_requests': 0,
                'average_response_time': 0,
                'total_response_time': 0
            }
        }
        
        for endpoint in self.test_endpoints:
            print(f"  ğŸ“¡ æµ‹è¯•ç«¯ç‚¹: {endpoint.path}")
            
            result = self.make_request(env_name, endpoint)
            env_results['endpoints'][endpoint.path] = result
            
            if result['success']:
                env_results['summary']['successful_requests'] += 1
                env_results['summary']['total_response_time'] += result.get('response_time', 0)
            else:
                env_results['summary']['failed_requests'] += 1
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        if env_results['summary']['successful_requests'] > 0:
            env_results['summary']['average_response_time'] = (
                env_results['summary']['total_response_time'] / 
                env_results['summary']['successful_requests']
            )
        
        return env_results

    def compare_api_responses(self, env1_results: Dict, env2_results: Dict) -> Dict[str, Any]:
        """æ¯”è¾ƒä¸¤ä¸ªç¯å¢ƒçš„APIå“åº”"""
        comparison = {
            'endpoint_comparisons': {},
            'summary': {
                'total_endpoints': len(self.test_endpoints),
                'consistent_endpoints': 0,
                'inconsistent_endpoints': 0,
                'response_time_diff': 0
            }
        }
        
        for endpoint in self.test_endpoints:
            path = endpoint.path
            env1_result = env1_results['endpoints'].get(path, {})
            env2_result = env2_results['endpoints'].get(path, {})
            
            endpoint_comparison = {
                'path': path,
                'description': endpoint.description,
                'env1_success': env1_result.get('success', False),
                'env2_success': env2_result.get('success', False),
                'status_code_match': False,
                'response_time_diff': 0,
                'data_consistency': 'unknown',
                'issues': []
            }
            
            # æ£€æŸ¥è¯·æ±‚æˆåŠŸæ€§
            if env1_result.get('success') and env2_result.get('success'):
                # æ¯”è¾ƒçŠ¶æ€ç 
                if env1_result.get('status_code') == env2_result.get('status_code'):
                    endpoint_comparison['status_code_match'] = True
                else:
                    endpoint_comparison['issues'].append(
                        f"çŠ¶æ€ç ä¸ä¸€è‡´: {env1_result.get('status_code')} vs {env2_result.get('status_code')}"
                    )
                
                # æ¯”è¾ƒå“åº”æ—¶é—´
                env1_time = env1_result.get('response_time', 0)
                env2_time = env2_result.get('response_time', 0)
                endpoint_comparison['response_time_diff'] = abs(env1_time - env2_time)
                
                # æ¯”è¾ƒå“åº”æ•°æ®
                env1_data = env1_result.get('data')
                env2_data = env2_result.get('data')
                
                if isinstance(env1_data, dict) and isinstance(env2_data, dict):
                    if env1_data == env2_data:
                        endpoint_comparison['data_consistency'] = 'consistent'
                        comparison['summary']['consistent_endpoints'] += 1
                    else:
                        endpoint_comparison['data_consistency'] = 'inconsistent'
                        endpoint_comparison['issues'].append("å“åº”æ•°æ®ä¸ä¸€è‡´")
                        comparison['summary']['inconsistent_endpoints'] += 1
                elif env1_data == env2_data:
                    endpoint_comparison['data_consistency'] = 'consistent'
                    comparison['summary']['consistent_endpoints'] += 1
                else:
                    endpoint_comparison['data_consistency'] = 'inconsistent'
                    endpoint_comparison['issues'].append("å“åº”æ•°æ®ä¸ä¸€è‡´")
                    comparison['summary']['inconsistent_endpoints'] += 1
            else:
                if not env1_result.get('success'):
                    endpoint_comparison['issues'].append(f"ç¯å¢ƒ1è¯·æ±‚å¤±è´¥: {env1_result.get('error', 'Unknown error')}")
                if not env2_result.get('success'):
                    endpoint_comparison['issues'].append(f"ç¯å¢ƒ2è¯·æ±‚å¤±è´¥: {env2_result.get('error', 'Unknown error')}")
            
            comparison['endpoint_comparisons'][path] = endpoint_comparison
        
        return comparison

    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢çš„APIä¸€è‡´æ€§æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ä¸‰ç¯å¢ƒAPIæ•°æ®ä¸€è‡´æ€§æµ‹è¯•...")
        
        # æµ‹è¯•æ¯ä¸ªç¯å¢ƒ
        for env_name in self.environments.keys():
            self.results['environments'][env_name] = self.test_environment_apis(env_name)
        
        # è¿›è¡Œç¯å¢ƒé—´æ¯”è¾ƒ
        print("\nğŸ”„ è¿›è¡Œç¯å¢ƒé—´APIå“åº”æ¯”è¾ƒ...")
        
        envs = list(self.environments.keys())
        for i in range(len(envs)):
            for j in range(i + 1, len(envs)):
                env1, env2 = envs[i], envs[j]
                
                print(f"ğŸ“Š æ¯”è¾ƒ {env1} å’Œ {env2} ç¯å¢ƒAPIå“åº”...")
                
                comparison = self.compare_api_responses(
                    self.results['environments'][env1],
                    self.results['environments'][env2]
                )
                
                self.results['comparisons'][f"{env1}_vs_{env2}"] = comparison
        
        # ç”Ÿæˆæ€»ç»“
        self.generate_summary()
        
        # ä¿å­˜ç»“æœ
        self.save_results()

    def generate_summary(self):
        """ç”Ÿæˆæµ‹è¯•æ€»ç»“"""
        print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æ€»ç»“...")
        
        summary = {
            'total_environments': len(self.environments),
            'total_endpoints': len(self.test_endpoints),
            'total_comparisons': len(self.results['comparisons']),
            'consistency_score': 0,
            'average_response_time': 0,
            'issues': [],
            'recommendations': []
        }
        
        # è®¡ç®—ä¸€è‡´æ€§å¾—åˆ†
        total_comparisons = 0
        consistent_comparisons = 0
        total_response_time = 0
        successful_requests = 0
        
        for comparison in self.results['comparisons'].values():
            summary_data = comparison['summary']
            total_comparisons += summary_data['total_endpoints']
            consistent_comparisons += summary_data['consistent_endpoints']
        
        # è®¡ç®—ç¯å¢ƒå“åº”æ—¶é—´
        for env_results in self.results['environments'].values():
            total_response_time += env_results['summary']['total_response_time']
            successful_requests += env_results['summary']['successful_requests']
        
        if total_comparisons > 0:
            summary['consistency_score'] = (consistent_comparisons / total_comparisons) * 100
        
        if successful_requests > 0:
            summary['average_response_time'] = total_response_time / successful_requests
        
        # æ”¶é›†é—®é¢˜
        for comparison_name, comparison in self.results['comparisons'].items():
            for endpoint_path, endpoint_comparison in comparison['endpoint_comparisons'].items():
                if endpoint_comparison['issues']:
                    summary['issues'].extend([
                        f"{comparison_name} - {endpoint_path}: {issue}"
                        for issue in endpoint_comparison['issues']
                    ])
        
        # ç”Ÿæˆå»ºè®®
        if summary['consistency_score'] >= 90:
            summary['recommendations'].append("âœ… APIæ•°æ®ä¸€è‡´æ€§è‰¯å¥½ï¼Œå¯ä»¥ç»§ç»­åç»­æµ‹è¯•")
        elif summary['consistency_score'] >= 70:
            summary['recommendations'].append("âš ï¸ å­˜åœ¨å°‘é‡APIä¸ä¸€è‡´ï¼Œå»ºè®®ä¿®å¤åç»§ç»­")
        else:
            summary['recommendations'].append("âŒ å­˜åœ¨ä¸¥é‡APIä¸ä¸€è‡´ï¼Œéœ€è¦å…¨é¢æ£€æŸ¥å’Œä¿®å¤")
        
        if summary['average_response_time'] > 2:
            summary['recommendations'].append("âš ï¸ APIå“åº”æ—¶é—´è¾ƒæ…¢ï¼Œå»ºè®®ä¼˜åŒ–æ€§èƒ½")
        
        self.results['summary'] = summary

    def save_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"api-consistency-test-{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report(filename)

    def generate_markdown_report(self, json_filename: str):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        md_filename = json_filename.replace('.json', '.md')
        
        with open(md_filename, 'w', encoding='utf-8') as f:
            f.write(f"# APIæ•°æ®ä¸€è‡´æ€§æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**æµ‹è¯•ç‰ˆæœ¬**: v1.0\n")
            f.write(f"**æ•°æ®æº**: {json_filename}\n\n")
            
            # æ·»åŠ æ€»ç»“
            summary = self.results['summary']
            f.write(f"## ğŸ“Š æµ‹è¯•æ€»ç»“\n\n")
            f.write(f"- **æµ‹è¯•ç¯å¢ƒæ•°**: {summary['total_environments']}\n")
            f.write(f"- **æµ‹è¯•ç«¯ç‚¹æ•°**: {summary['total_endpoints']}\n")
            f.write(f"- **æ¯”è¾ƒæ¬¡æ•°**: {summary['total_comparisons']}\n")
            f.write(f"- **ä¸€è‡´æ€§å¾—åˆ†**: {summary['consistency_score']:.1f}%\n")
            f.write(f"- **å¹³å‡å“åº”æ—¶é—´**: {summary['average_response_time']:.3f}ç§’\n\n")
            
            # æ·»åŠ é—®é¢˜åˆ—è¡¨
            if summary['issues']:
                f.write(f"## âš ï¸ å‘ç°çš„é—®é¢˜\n\n")
                for issue in summary['issues']:
                    f.write(f"- {issue}\n")
                f.write("\n")
            
            # æ·»åŠ å»ºè®®
            f.write(f"## ğŸ’¡ å»ºè®®\n\n")
            for recommendation in summary['recommendations']:
                f.write(f"- {recommendation}\n")
            f.write("\n")
            
            # æ·»åŠ ç¯å¢ƒè¯¦æƒ…
            f.write(f"## ğŸŒ ç¯å¢ƒè¯¦æƒ…\n\n")
            for env_name, env_results in self.results['environments'].items():
                env_summary = env_results['summary']
                f.write(f"### {self.environments[env_name]['name']}\n\n")
                f.write(f"- **åŸºç¡€URL**: {env_results['base_url']}\n")
                f.write(f"- **æˆåŠŸè¯·æ±‚**: {env_summary['successful_requests']}/{env_summary['total_endpoints']}\n")
                f.write(f"- **å¹³å‡å“åº”æ—¶é—´**: {env_summary['average_response_time']:.3f}ç§’\n\n")
            
            # æ·»åŠ è¯¦ç»†æ¯”è¾ƒç»“æœ
            f.write(f"## ğŸ” è¯¦ç»†æ¯”è¾ƒç»“æœ\n\n")
            for comparison_name, comparison in self.results['comparisons'].items():
                f.write(f"### {comparison_name}\n\n")
                
                summary_data = comparison['summary']
                f.write(f"- **ä¸€è‡´æ€§ç«¯ç‚¹**: {summary_data['consistent_endpoints']}/{summary_data['total_endpoints']}\n")
                f.write(f"- **ä¸ä¸€è‡´ç«¯ç‚¹**: {summary_data['inconsistent_endpoints']}/{summary_data['total_endpoints']}\n\n")
                
                for endpoint_path, endpoint_comparison in comparison['endpoint_comparisons'].items():
                    status = "âœ…" if endpoint_comparison['data_consistency'] == 'consistent' else "âŒ"
                    f.write(f"#### {endpoint_path} {status}\n\n")
                    f.write(f"- **æè¿°**: {endpoint_comparison['description']}\n")
                    f.write(f"- **æ•°æ®ä¸€è‡´æ€§**: {endpoint_comparison['data_consistency']}\n")
                    f.write(f"- **å“åº”æ—¶é—´å·®å¼‚**: {endpoint_comparison['response_time_diff']:.3f}ç§’\n")
                    
                    if endpoint_comparison['issues']:
                        f.write(f"- **é—®é¢˜**:\n")
                        for issue in endpoint_comparison['issues']:
                            f.write(f"  - {issue}\n")
                    f.write("\n")
            
            f.write(f"---\n\n")
            f.write(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        print(f"ğŸ“„ MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {md_filename}")

def main():
    tester = APIConsistencyTester()
    tester.run_comprehensive_test()
    
    # æ˜¾ç¤ºæ€»ç»“
    summary = tester.results['summary']
    print(f"\nğŸ¯ APIä¸€è‡´æ€§æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š ä¸€è‡´æ€§å¾—åˆ†: {summary['consistency_score']:.1f}%")
    print(f"â±ï¸ å¹³å‡å“åº”æ—¶é—´: {summary['average_response_time']:.3f}ç§’")
    print(f"ğŸ“‹ å‘ç°é—®é¢˜: {len(summary['issues'])} ä¸ª")
    
    for recommendation in summary['recommendations']:
        print(f"ğŸ’¡ {recommendation}")

if __name__ == "__main__":
    main()
